table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
library(caret)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
rm(list=ls())
# default r markdown global options in document
knitr::opts_chunk$set(
########## Text results ##########
echo=TRUE,
warning=FALSE, # to preserve warnings in the output
error=FALSE, # to preserve errors in the output
message=FALSE, # to preserve messages
strip.white=TRUE, # to remove the white lines in the beginning or end of a source chunk in the output
########## Cache ##########
cache=TRUE,
########## Plots ##########
fig.path="", # prefix to be used for figure filenames
fig.width=8,
fig.height=6,
dpi=200
)
library(ISLR)
library(e1071) # svm() function
library(ggplot2)
library(caret)
set.seed(1)
x<-matrix(rnorm(20*2), ncol=2)
y<-c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,]+1
plot(x, col=(3-y)) # check whether the classes are linearly separable -> They are not separable.
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=10, scale=FALSE) # kernel: linear/polynomial/radial basis/sigmoid, cost: cost of constraints violation (default:1) - "C" constant of the regularization term in the Lagrange formulation
plot(svmfit,dat) # -1: blue, 1: purple
svmfit$index
summary(svmfit)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit,dat) # -1: blue, 1: purple
svmfit$index
summary(svmfit)
set.seed(1)
tune.out<-tune(svm, y~., data=dat, kernel="linear",
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100))) # ranges: list of parameter vectors spanning the sampling space
summary(tune.out)
bestmod<-tune.out$best.model
summary(bestmod)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit,dat) # -1: blue, 1: purple
svmfit$index
summary(svmfit)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit,dat) # -1: blue, 1: purple
svmfit$index
summary(svmfit)
set.seed(1)
tune.out<-tune(svm, y~., data=dat, kernel="linear",
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100))) # ranges: list of parameter vectors spanning the sampling space
summary(tune.out)
bestmod<-tune.out$best.model
summary(bestmod)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.01, scale=FALSE)
ypred<-predict(svmfit, testdat)
confusionMatrix(ypred, testdat$y)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit,dat) # -1: blue, 1: purple
svmfit$index
summary(svmfit)
set.seed(1)
tune.out<-tune(svm, y~., data=dat, kernel="linear",
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100))) # ranges: list of parameter vectors spanning the sampling space
summary(tune.out)
bestmod<-tune.out$best.model
summary(bestmod)
set.seed(1)
x<-matrix(rnorm(20*2), ncol=2)
y<-c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,]+1
plot(x, col=(3-y)) # check whether the classes are linearly separable -> They are not separable.
dat<-data.frame(x=x, y=as.factor(y))
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.01, scale=FALSE)
ypred<-predict(svmfit, testdat)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.01, scale=FALSE)
ypred<-predict(svmfit, testdat)
confusionMatrix(ypred, testdat$y)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.01, scale=FALSE)
ypred<-predict(svmfit, testdat)
confusionMatrix(ypred, testdat$y)
svmfit<-svm(y~., data=dat, kernel="linear", cost=0.01, scale=FALSE)
ypred<-predict(svmfit, testdat)
confusionMatrix(ypred, testdat$y)
x[y==1,]=x[y==1,]+0.5
plot(x, col(y+5)/2, pch=19)
x[y==1,]=x[y==1,]+0.5
plot(x, col(y+5)/2, pch=19)
x[y==1,]=x[y==1,]+0.5
plot(x, col(y+5)/2, pch=19)
x[y==1,]=x[y==1,]+0.5
plot(x, col(y+5)/2, pch=19)
x[y==1,]=x[y==1,]+0.5
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
svmfit<-svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit, dat)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e100)
summary(svmfit)
plot(svmfit, dat)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat<-data.frame(x=x, y=as.factor(y))
svmfit<-svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
plot(svmfit, dat)
svmfit<-svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit, dat)
plot(svmfit, dat)
svmfit<-svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit, dat)
qe5
1e5
1000/1e5
set.seed(1)
tune.out<-tune(svm, y~., data=dat, kernel="linear",
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100))) # ranges: list of parameter vectors spanning the sampling space
summary(tune.out)
bestmod<-tune.out$best.model
summary(bestmod)
plot(tune.out)
tune.out$best.performance
tune.out$best.parameters
summary(tune.out)
plot(tune.out)
plot(tune.out, ylim=c(0,0.1))
plot(tune.out, ylim=c(0,0.1))
plot(tune.out, ylim=c(0,0.1))
plot(tune.out, ylim=c(0,0.05))
plot(tune.out, ylim=c(0,0.05))
plot(tune.out)
tune.out$best.parameters
bestmod<-tune.out$best.model
summary(bestmod)
set.seed(1)
xtest<-matrix(rnorm(20*2), ncol=2)
ytest<-sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod, testdat)
table(ypred, testdat$y)
confusionMatrix(ypred, testdat$y)
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150), rep(2,50))
dat<-data.frame(x=x, y=as.factor(y))
plot(x,col=(y))
y
table(y)
table(x)
?svm
train<-sample(200,100)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train,])
plot(svmfit, dat[train,])
train<-sample(200,100)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train,])
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150), rep(2,50))
dat<-data.frame(x=x, y=as.factor(y))
plot(x,col=(y))
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150), rep(2,50))
dat<-data.frame(x=x, y=as.factor(y))
plot(x,col=(y)) # The class boundary is non-linear
train<-sample(200,100)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train,])
train<-sample(200,100)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1e5)
plot(svmfit, dat[train,])
summary(svmfit)
set.seed(1)
tune.out<-tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(
cost=c(0.1, 1, 10, 100, 1000),
gamma=c(0.5, 1,2,3,4)))
summary(tune.out)
tune.out$best.parameters
tune.out$best.parameters
tune.out$best.model
tune.out$best.parameters
tune.out$best.parameters
summary(tune.out)
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150), rep(2,50))
dat<-data.frame(x=x, y=as.factor(y))
plot(x,col=(y)) # The class boundary is non-linear
train<-sample(200,100)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit<-svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1e5)
plot(svmfit, dat[train,])
summary(svmfit)
set.seed(1)
tune.out<-tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(
cost=c(0.1, 1, 10, 100, 1000),
gamma=c(0.5, 1,2,3,4)))
summary(tune.out)
tune.out$best.parameters
set.seed(1)
tune.out<-tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(
cost=c(0.1, 1, 10, 100, 1000),
gamma=c(0.5, 1,2,3,4)))
summary(tune.out)
tune.out$best.parameters
svm.pred<-predict(tune.out$best.model, newdata=dat[-train,])
table(dat[-train,"y"], svm.pred)
confusionMatrix(dat[-train,"y"], svm.pred)
set.seed(1)
tune.out<-tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(
cost=c(0.1, 1, 10, 100, 1000),
gamma=c(0.5, 1,2,3,4)))
summary(tune.out)
tune.out$best.parameters
svm.pred<-predict(tune.out$best.model, newx=dat[-train,])
table(dat[-train,"y"], svm.pred)
confusionMatrix(dat[-train,"y"], svm.pred)
set.seed(1)
tune.out<-tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(
cost=c(0.1, 1, 10, 100, 1000),
gamma=c(0.5, 1,2,3,4)))
summary(tune.out)
tune.out$best.parameters
svm.pred<-predict(tune.out$best.model, newx=dat[-train,])
table(dat[-train,"y"], svm.pred)
confusionMatrix(dat[-train,"y"], svm.pred)
?predict.newx
newx
svm.pred<-predict(tune.out$best.model, newx=dat[-train,])
table(dat[-train,"y"], svm.pred)
confusionMatrix(dat[-train,"y"], svm.pred)
install.packages("ROCR")
library(ISLR)
library(e1071) # svm() function
library(ggplot2)
library(caret)
library(ROCR)
?performance
rocplot<-function(pred, truth, ...) {
predob<-prediction(pred, truth)
perf<-performance(predob, "tpr", "fpr")
plot(perf, ...)}
?svm
svm.pred<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
fitted<-attributes(svm.pred$decision.values)
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
fitted<-attributes(svm.pred)$decision.values
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
fitted<-attributes(svm.pred)$decision.values
par(mfrow=c(1,2))
rocplot(fitted, dat[train,"y"])
?rocplot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
fitted<-attributes(svm.pred)$decision.values
par(mfrow=c(1,2))
rocplot(fitted, dat[train,"y"])
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
par(mfrow=c(1,2))
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data") # ROC plot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
par(mfrow=c(1,2))
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", add=T) # ROC plot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
par(mfrow=c(1,2))
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", add=T, col="red") # ROC plot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", add=T, col="red") # ROC plot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", add=T, col="red") # ROC plot
legend("topright", lty=1, text=c("s"))
?legend
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", add=T, col="red") # ROC plot
legend("topright")
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
par(mfrow=c(1,2))
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", col="red") # ROC plot
svmfit.opt<-svm(y~., data=dat[train,], kernel="radial", gamma=2, cost=1, decision.values=TRUE)
svm.pred1<-predict(svmfit.opt, dat[train,], decision.values=TRUE)
svm.pred2<-predict(svmfit.opt, dat[-train,], decision.values=TRUE)
fitted1<-attributes(svm.pred1)$decision.values
fitted2<-attributes(svm.pred2)$decision.values
par(mfrow=c(1,2))
rocplot(fitted1, dat[train,"y"], main="Training Data") # ROC plot
rocplot(fitted2, dat[train,"y"], main="Test Data", col="red") # ROC plot
set.seed(1)
x<-rbind(x, matrix(rnorm(50*2), ncol=2))
y<-c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat<-data.frame(x=x, y=as.factor(y))
plot(x, col=y+1)
set.seed(1)
x<-rbind(x, matrix(rnorm(50*2), ncol=2))
y<-c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat<-data.frame(x=x, y=as.factor(y))
plot(x, col=y+1, pch=19)
View(dat)
set.seed(1)
x<-rbind(x, matrix(rnorm(50*2), ncol=2))
y<-c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat<-data.frame(x=x, y=as.factor(y))
plot(x, col=y+1, pch=19)
svmfit<-svm(y~., data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit, dat)
table(Khan$ytrain)
table(Khan$ytest)
names(Khan)
dat<-data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out<-svm(y~., data=dat, kernel="linear", cost=10)
summary(out)
dat<-data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out<-svm(y~., data=dat, kernel="linear", cost=10)
out<-svm(y~., data=dat, kernel="linear", cost=10)
summary(out)
dat<-data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out<-svm(y~., data=dat, kernel="linear", cost=10)
summary(out)
table(out$fitted, dat$y)
confusionMatrix(out$fitted, dat$y)
dat<-data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
dat.test<-data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred<-predict(out, newdata=dat.test)
table(pred, dat.test$y)
confusionMatrix(out$fitted, dat$y)
dat<-data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out<-svm(y~., data=dat, kernel="linear", cost=10)
dat.test<-data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred<-predict(out, newdata=dat.test)
table(pred, dat.test$y)
confusionMatrix(out$fitted, dat$y)

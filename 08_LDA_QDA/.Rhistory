knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
attach(Smarket)
train<-Smarket$Year<2005 # Boolean vector
train.X<-cbind(Lag1, Lag2)[train,]
test.X<-cbind(Lag1, Lag2)[!train,]
train.Direction<-Direction[train]
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=1,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Direction, k=10,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, Smarket$Direction[!train])
mean(knn.pred==Smarket$Direction[!train])
summary(Caravan) # Caravan insurance data from ISLR library
head(Caravan,3)
Caravan<-na.omit(Caravan)
dim(Caravan)
names(Caravan)
?scale
std.X<-scale(Caravan[,-86])
var(Caravan[,1]); var(std.X[,1])
var(Caravan[,10]); var(std.X[,10])
std.X<-scale(Caravan[,-86]) # Scaling the features to mean of zero and standard deviation of one
var(Caravan[,1]); var(std.X[,1])
var(Caravan[,10]); var(std.X[,10])
std.X<-scale(Caravan[,-86]) # scaling the columns of Caravan (except of the 86th column which is qualitative variable) to mu 0 and sd 1
var(Caravan[,1]); var(std.X[,1]) # Comparing original vs. standardized data
var(Caravan[,10]); var(std.X[,10])
std.X<-scale(Caravan[,-86]) # scaling the columns of Caravan (except of the 86th column which is qualitative variable) to mu 0 and sd 1
var(Caravan[,1]); var(std.X[,1]) # Comparing original vs. standardized data
var(Caravan[,10]); var(std.X[,10])
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test,]
Caravan$Purchase
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test,]
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Caravan$Purchase[-test,]
class(std.X)
std.X
dim(std.X)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=1,prob=F, use.all=T) # knn classification for test set from training set.
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test]
test.Y<-Purchase[test]
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test]
test.Y<-Purchase[test]
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=1,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
mean(knn.pred==test.Y)
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test]
test.Y<-Purchase[test]
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=1,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
mean(knn.pred==test.Y)
table(Caravan$Purchase)
(348/(5474+348))
mean(knn.pred!==test.Y)
mean(knn.pred!=test.Y)
table(knn.pred, test.Y)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
mean(knn.pred!=test.Y)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
mean(knn.pred!=test.Y)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
mean(knn.pred!=test.Y)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=3,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
4/15
table(Caravan$Purchase)
attach(Smarket)
table(Purchase)
train<-Smarket$Year<2005 # Boolean vector
train.X<-cbind(Lag1, Lag2)[train,]
test.X<-cbind(Lag1, Lag2)[!train,]
train.Direction<-Direction[train]
348/(5474+348)
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test]
test.Y<-Purchase[test]
set.seed(1)
knn.pred<-knn(train=train.X, test=test.X, cl=train.Y, k=5,prob=F, use.all=T) # knn classification for test set from training set.
table(knn.pred, test.Y)
glm.fit<-glm(Purchase~., data=Caravan, family=binommial, subset=-test)
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
attach(Caravan)
test<-1:1000
train.X<-std.X[-test,]
test.X<-std.X[test,]
train.Y<-Purchase[-test]
test.Y<-Purchase[test]
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=test)
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
table(glm.pred, Caravan$Purchase[test])
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
threshold<-.5
glm.pred.class<-as.factor(ifelse(glm.pred>threshold, "1","0"))
table(glm.pred, Caravan$Purchase[test])
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
threshold<-.5
glm.pred.class<-as.factor(ifelse(glm.pred>threshold, "1","0"))
table(glm.pred.class, Caravan$Purchase[test])
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
threshold<-.5
glm.pred.class<-as.factor(ifelse(glm.pred>threshold, "Yes","No"))
table(glm.pred.class, Caravan$Purchase[test])
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
threshold<-.25
glm.pred.class<-as.factor(ifelse(glm.pred>threshold, "Yes","No"))
table(glm.pred.class, Caravan$Purchase[test])
glm.fit<-glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.pred<-predict(glm.fit, newdata=Caravan[test,], type="response")
threshold<-.25
glm.pred.class<-as.factor(ifelse(glm.pred>threshold, "Yes","No"))
table(glm.pred.class, Caravan$Purchase[test])
sample(10,2)
sample(-10,2)
sample(2,2)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
sample(2,2,replace=T)
set.seed(100)
sample(2,2,replace=T)
set.seed(100)
sample(2,2,replace=T)
set.seed(100)
sample(2,2,replace=T)
summary(Auto) # Stock market data from ISLR library
head(Auto,3)
Auto<-na.omit(Auto)
dim(Auto)
Auto$mpg[-train
Auto$mpg[-train]
Auto$mpg[-train]
mean(Auto$mpg[-train]-predict(lm.fit, data=Auto[-train]))^2
mean(Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train]))^2
mean(Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,]))^2
predict(lm.fit, newdata=Auto[-train,])
lm.fit<-lm(mpg~horsepower, data=Auto, subset=train)
mean(Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,]))^2
mean((Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,])^2)
mean((Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,])^2))
Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,])
mean((Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,]))^2)
dim(Auto)
392/2
summary(Auto) # Stock market data from ISLR library
head(Auto,3)
train<-sample(392,196) # selecting a random subset of 196 observations out of the original 392 observations.
lm.fit<-lm(mpg~horsepower, data=Auto, subset=train)
mean((Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,]))^2) # MSE
summary(Auto) # Stock market data from ISLR library
head(Auto,3)
Auto<-na.omit(Auto)
dim(Auto)
set.seed(1)
train<-sample(392,196) # selecting a random subset of 196 observations out of the original 392 observations.
lm.fit<-lm(mpg~horsepower, data=Auto, subset=train)
mean((Auto$mpg[-train]-predict(lm.fit, newdata=Auto[-train,]))^2) # MSE
lm.fit2<-lm(mpg~poly(horsepower,2), data=Auto, subset=train)
mean((Auto$mpg[-train]-predict(lm.fit2, newdata=Auto[-train,]))^2) # MSE
lm.fit2<-lm(mpg~poly(horsepower,3), data=Auto, subset=train)
mean((Auto$mpg[-train]-predict(lm.fit3, newdata=Auto[-train,]))^2) # MSE
lm.fit3<-lm(mpg~poly(horsepower,3), data=Auto, subset=train)
mean((Auto$mpg[-train]-predict(lm.fit3, newdata=Auto[-train,]))^2) # MSE
library(ISLR)
library(boot)
glm.fit<-glm(mpg~horsepower, data=Auto)
cv.err<-cv.glm(Auto, glm.fit)
glm.fit<-glm(mpg~horsepower, data=Auto)
cv.err<-cv.glm(Auto, glm.fit)
cv.err
?cv.glm
cv.err
cv.err$delta
for (i in 1:5) {
cv.err<-vector()
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
cv.err
for (i in 1:5) {
cv.err<-rep(0,5)
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
cv.err
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
library(ISLR)
library(boot) # function cv.glm()
summary(Auto) # Stock market data from ISLR library
head(Auto,3)
Auto<-na.omit(Auto)
dim(Auto)
set.seed(1)
train<-sample(392,196) # selecting a random subset of 196 observations out of the original 392 observations.
for (i in 1:5) {
cv.err<-vector()
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
cv.err
glm.fit<-glm(mpg~poly(horsepower,3), data=Auto)
cv.err<-cv.glm(data=Auto, glmfit=glm.fit)$delta
cv.err
cv.err<-vector()
for (i in 1:5) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
cv.err
ggplot(cv.err)+geom_jitter()
ggplot(aes(y=cv.err, x=1:5))+geom_jitter()
df_cv<-data.frame(x=c(1:5), y=cv_err)
cv.err<-vector()
for (i in 1:5) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
df_cv<-data.frame(x=c(1:5), y=cv_err)
df_cv<-data.frame(x=c(1:5), y=cv.err)
ggplot(data=df_cv, aes(y=y, x=x))+geom_jitter()
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_jitter()
df_cv<-data.frame(order=c(1:5), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_jitter()
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_line()
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_jitter()
cv.err<-vector()
for (i in 1:5) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit)$delta[1]
}
df_cv<-data.frame(order=c(1:5), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_jitter()
View(df_cv)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.err<-vector()
for (i in 1:5) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1]
}
df_cv<-data.frame(order=c(1:5), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.glm(data=Auto, glmfit=glm.fit, K=10)
cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1]
cv.glm(data=Auto, glmfit=glm.fit)
length(cv.glm(data=Auto, glmfit=glm.fit))
glm.fit<-glm(mpg~poly(horsepower,3), data=Auto)
cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1:5]
cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta
?cv.glm
glm.fit<-glm(mpg~poly(horsepower,5), data=Auto)
cv.glm(data=Auto, glmfit=glm.fit, K=3)
class(cv.err)
length(cv.err)
attributes(cv.err)
cv.err$delta
cv.err<-cv.glm(data=Auto, glmfit=glm.fit, K=3)$delta
cv.err
cv.err<-cv.glm(data=Auto, glmfit=glm.fit, K=3)
cv.err
cv.err$delta
cv.err<-vector()
for (i in 1:5) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1] # mean k estimates of test error
}
df_cv<-data.frame(order=c(1:5), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.err<-vector()
for (i in 1:10) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1] # mean k estimates of test error
}
df_cv<-data.frame(order=c(1:10), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.err<-vector()
for (i in 1:10) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=15)$delta[1] # mean k estimates of test error
}
df_cv<-data.frame(order=c(1:10), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.err<-vector()
for (i in 1:10) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=15)$delta[1] # mean k estimates of test error
}
df_cv<-data.frame(order=c(1:10), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
cv.err<-vector()
for (i in 1:10) {
glm.fit<-glm(mpg~poly(horsepower,i), data=Auto)
cv.err[i]<-cv.glm(data=Auto, glmfit=glm.fit, K=10)$delta[1] # mean k estimates of test error
}
df_cv<-data.frame(order=c(1:10), cv.err=cv.err)
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
ggplot(data=df_cv, aes(y=cv.err, x=order))+geom_point()
library(ISLR)
library(boot) # function boot()
library(ggplot2)
summary(Portfolio) # Stock market data from ISLR library
head(Portfolio,3)
Portfolio<-na.omit(Portfolio)
dim(Portfolio)
rm(list=ls())
# default r markdown global options in document
knitr::opts_chunk$set(
########## Text results ##########
echo=TRUE,
warning=FALSE, # to preserve warnings in the output
error=FALSE, # to preserve errors in the output
message=FALSE, # to preserve messages
strip.white=TRUE, # to remove the white lines in the beginning or end of a source chunk in the output
########## Cache ##########
cache=TRUE,
########## Plots ##########
fig.path="", # prefix to be used for figure filenames
fig.width=8,
fig.height=6,
dpi=200
)
library(ISLR)
library(boot) # function boot()
library(ggplot2)
summary(Portfolio) # Stock market data from ISLR library
head(Portfolio,3)
Portfolio<-na.omit(Portfolio)
dim(Portfolio)
View(Portfolio)
alpha<-function(data, index) {
x<-data$x[index]
y<-data$y[index]
alpha<-(var(y)-cov(x,y))/(var(x)+var(y)-2*cov(x,y))
return(alpha)
}
alpha(Portfolio, 1:100)
View(alpha)
alpha<-function(data, index) {
x<-data$X[index]
y<-data$Y[index]
alpha<-(var(y)-cov(x,y))/(var(x)+var(y)-2*cov(x,y))
return(alpha)
}
alpha(Portfolio, 1:100)
alpha(Portfolio, sample(100,100, replace=TRUE))
alpha<-function(data, index) {
x<-data$X[index]
y<-data$Y[index]
alpha<-(var(y)-cov(x,y))/(var(x)+var(y)-2*cov(x,y))
return(alpha)
}
alpha(Portfolio, 1:100)
set.seed(1)
alpha(Portfolio, sample(100,100, replace=TRUE))
?boot
boot(data=Portfolio, statistic=alpha, R=1000)
boot(data=Portfolio, statistic=alpha, R=1000)
boot(data=Portfolio, statistic=alpha, R=1000)
set.seed(1)
boot(data=Portfolio, statistic=alpha, R=1000)
set.seed(1)
boot.fn<-function(data, index) {
return(coef(lm(mpg~horsepower, data=data, subset=index)))
}
set.seed(1)
boot.fn(data=Auto,sample(392,392,replace=TRUE) )
boot(data=Auto, statistic=boot.fn, R=1000)
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower,data=Auto))$coef
boot(data=Auto, statistic=boot.fn, R=1000)
set.seed(1)
boot.fn<-function(data, index) {
return(coef(lm(mpg~horsepower+I(horsepower^2), data=data, subset=index)))
}
set.seed(1)
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower+I(horsepower^2), data=Auto))$coef
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower,data=Auto))$coef
set.seed(1)
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower,data=Auto))$coef
set.seed(1)
boot.fn<-function(data, index) {
return(coef(lm(mpg~horsepower, data=data, subset=index)))
}
set.seed(1)
boot.fn(data=Auto,sample(392,392,replace=TRUE))
set.seed(1)
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower,data=Auto))$coef
set.seed(1)
boot.fn<-function(data, index) {
return(coef(lm(mpg~horsepower+I(horsepower^2), data=data, subset=index)))
}
set.seed(1)
boot(data=Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower+I(horsepower^2), data=Auto))$coef
set.seed(1)
boot.fn<-function(data, index) {
return(summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared)
}
set.seed(1)
boot.fn<-function(data, index) {
return(summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared)
}
boot(Auto, statistic=boot.fn, R=1000)
set.seed(1)
boot.fn<-function(data, index) {
return(summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared)
}
boot(Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared
set.seed(1)
boot.fn<-function(data, index) {
return(summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared)
}
boot(Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower, data=Auto))$adj.r.squared
set.seed(1)
boot.fn<-function(data, index) {
return(summary(lm(mpg~horsepower, data=data, subset=index))$adj.r.squared)
}
boot(Auto, statistic=boot.fn, R=1000)
summary(lm(mpg~horsepower, data=Auto))

---
title: "<center> Subset Selection </center>"
output:
  html_document:
    fig_height: 4
    highlight: pygments
    theme: spacelab
  pdf_document: default
---
<center> <h3> Sunah Park </center>

This markdown file is created by Sunah Park for extended lab exercises in the book _An Introduction to Statistical Learning with Applications in R_ [(ISLR)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf). 


* * *

### Setup for code chunks
```{r mychunksetup, echo=TRUE, include=TRUE} 
rm(list=ls())
# default r markdown global options in document
knitr::opts_chunk$set(
   ########## Text results ##########
    echo=TRUE, 
    warning=FALSE, # to preserve warnings in the output 
    error=FALSE, # to preserve errors in the output
    message=FALSE, # to preserve messages
    strip.white=TRUE, # to remove the white lines in the beginning or end of a source chunk in the output 

    ########## Cache ##########
    cache=TRUE,
   
    ########## Plots ##########
    fig.path="", # prefix to be used for figure filenames
    fig.width=8,
    fig.height=6,
    dpi=200
)
```



* * * 
```{r lib, echo=TRUE, include=TRUE} 
library(ISLR)
library(leaps) # regsubsets() function
library(ggplot2)
```


```{r df, echo=TRUE, include=TRUE} 
summary(Hitters) # Hitters data from ISLR library
head(Hitters,3)
Hitters<-na.omit(Hitters)
dim(Hitters)
```

## __Best Subset Selection__
```{r bss, echo=TRUE, include=TRUE} 
regfit.full<-regsubsets(Salary~., data=Hitters) # from leaps library
summary(regfit.full)

nvmax<-19 # 20-1=19 maximum predictors
regfit.full<-regsubsets(Salary~., data=Hitters, nvmax=nvmax) #nvmax can be used in order to return as many variables as are desired (=maximum size of subsets to examine)
summary(regfit.full)

names(summary(regfit.full))
```

The regsubsets() function performs best subset selection by identifying the best model that contains a given number of predictors, where best is quantified using RSS. An asterisk indicates that a given variable is included in the corresponding model. For instance, this output indicates that the best two-variable model contains only Hits and CRBI. By default, regsubsets() only reports results up to the best eight-variable model. But the nvmax option can be used in order to return as many variables as are desired. 

The summary() function returns R^2, RSS, adjusted R^2, Cp and BIC. We can examine these to try to select the best overall model. For instance, we see that the R^2 statistic increases from 32%, when only one variable is included in the model, to almost 55% when all variables are included. As expected, the R^2 statistic increases monotonically as more variables are included.


```{r full, echo=TRUE, include=TRUE} 
df_full<-data.frame(i=seq(1:nvmax),
               rsq=summary(regfit.full)$rsq,
               rss=summary(regfit.full)$rss,
               adjr2=summary(regfit.full)$adjr2,
               cp=summary(regfit.full)$cp,
               bic=summary(regfit.full)$bic)


# R-squared
ggplot(data=df_full, aes(x=i, y=rsq))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="R-squared")
plot(regfit.full, scale="r2")

# Residual Sum of Squares
ggplot(data=df_full, aes(x=i, y=rss))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Residual Sum of Squares")

# adjusted R-squared
ggplot(data=df_full, aes(x=i, y=adjr2))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Adjusted R-Squared")
plot(regfit.full, scale="adjr2")

# cp
ggplot(data=df_full, aes(x=i, y=cp))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Mallows' Cp")
plot(regfit.full, scale="Cp")

# bic
ggplot(data=df_full, aes(x=i, y=bic))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="BIC")
plot(regfit.full, scale="bic")
coef(regfit.full,6)
```

The regsubsets() function has a built-in plot() command which can be used to display the selected variables for the best model with a given number of predictors, ranked according to the BIC, Cp, adjusted R^2, or AIC (?plot.regsubsets). The top row of each plot contains a black square for each variable selected according to the optimal model associated with that statistic. 



## __Forward and Backward Stepwise Selection__
We can also use the regsubsets() function to perform forward stepwise or backward stepwise selection, using the argument method="forward" or method="backward". 
Backward selection requires that the number of samples n is larger than the number of variables p (so that the full model can be fit). In contrast, forward stepwise can be used even when n is smaller than p, and so is the only viable subset method when p is very large. 

__Forward stepwise selection__ is computationally efficient alternative to best subset selection. While the best subset selection procedure considers all 2^p possible models containing subsets of the p predictors, forward stepwise considers a much smaller set of models. Forward stepwise selection begins with a model containing no predictors, and then adds predictors to the model, one-at-time, until all of the predictors are in the model. In particular, at each step the variable that gives the greatest additional improvement to the fit is added to the model.

```{r fwd, echo=TRUE, include=TRUE} 
regfit.fwd<-regsubsets(Salary~., data=Hitters, nvmax=nvmax, method="forward") # from leaps library
summary(regfit.fwd)

df_fwd<-data.frame(i=seq(1:nvmax),
               rsq=summary(regfit.fwd)$rsq,
               rss=summary(regfit.fwd)$rss,
               adjr2=summary(regfit.fwd)$adjr2,
               cp=summary(regfit.fwd)$cp,
               bic=summary(regfit.fwd)$bic)


# R-squared
ggplot(data=df_fwd, aes(x=i, y=rsq))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="R-squared")
plot(regfit.fwd, scale="r2")

# Residual Sum of Squares
ggplot(data=df_fwd, aes(x=i, y=rss))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Residual Sum of Squares")

# adjusted R-squared
ggplot(data=df_fwd, aes(x=i, y=adjr2))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Adjusted R-Squared")
plot(regfit.fwd, scale="adjr2")

# cp
ggplot(data=df_fwd, aes(x=i, y=cp))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Mallows' Cp")
plot(regfit.fwd, scale="Cp")

# bic
ggplot(data=df_fwd, aes(x=i, y=bic))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="BIC")
plot(regfit.fwd, scale="bic")
```

__Backward stepwise selection__ provides an efficient alternative to best subset selection. However, unlike forward stepwise selection, it begins with the full least squares model containing all p predictors, and then iteratively removes the least useful predictor, one-at-a-time. 

```{r bwd, echo=TRUE, include=TRUE} 
regfit.bwd<-regsubsets(Salary~., data=Hitters, nvmax=nvmax, method="backward") # from leaps library
summary(regfit.bwd)

df_bwd<-data.frame(i=seq(1:nvmax),
                   rsq=summary(regfit.bwd)$rsq,
                   rss=summary(regfit.bwd)$rss,
                   adjr2=summary(regfit.bwd)$adjr2,
                   cp=summary(regfit.bwd)$cp,
                   bic=summary(regfit.bwd)$bic)


# R-squared
ggplot(data=df_bwd, aes(x=i, y=rsq))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="R-squared")
plot(regfit.bwd, scale="r2")

# Residual Sum of Squares
ggplot(data=df_bwd, aes(x=i, y=rss))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Residual Sum of Squares")

# adjusted R-squared
ggplot(data=df_bwd, aes(x=i, y=adjr2))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Adjusted R-Squared")
plot(regfit.bwd, scale="adjr2")

# cp
ggplot(data=df_bwd, aes(x=i, y=cp))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="Mallows' Cp")
plot(regfit.bwd, scale="Cp")

# bic
ggplot(data=df_bwd, aes(x=i, y=bic))+geom_line()+geom_point(pch=4,col="red")+coord_cartesian(x=c(0,nvmax))+labs(x="Number of Predictors", y="BIC")
plot(regfit.bwd, scale="bic")
```


## __Choosing among models using the Validation Set Approach and Cross-Validation__
To yield accurate estimates for the test error, we must use only the training observations to perform all aspects of model-fitting-including variable selection. Therefore, the determination of which model of a given size is best must be made using only the training observations. If the full data set is used to perform the best subset selection step, the validaiton set errors and cross-validation errors that we obtain will not be accurate estimates of the test error. 

```{r split, echo=TRUE, include=TRUE} 
set.seed(1)
train<-sample(c(T,F), nrow(Hitters),rep=TRUE)
test<-!train

regfit.best<-regsubsets(Salary~., data=Hitters[train,], nvmax=19) # regsubsets() to the training set in order to perfor best subset selection

test.mat<-model.matrix(Salary~., data=Hitters[test,])
```

model.matrix() function is used in many regression packages for building an "X" matrix from data. Now we run a loop, and for each size i, we extract the coefficients from regfit.best for the best model of that size, multiply them into the appropriate columns of the test model matrix to form the predictions, and compute the test MSE.

```{r val, echo=TRUE, include=TRUE} 
regfit.best<-regsubsets(Salary~., data=Hitters, nvmax=19)
val.errors<-rep(NA,19)
for (i in 1:19) {
    coefi<-coef(regfit.best, id=i)
    pred<-test.mat[, names(coefi)]%*%coefi
    val.errors[i]<-mean((Hitters$Salary[test]-pred)^2)
}
coef(regfit.best, which.min(val.errors))
```


```{r val2, echo=TRUE, include=TRUE} 
predict.regsubsets<-function(object, newdata, id, ...) {
    form<-as.formula(object$call[[2]])
    mat<-model.matrix(form, newdata)
    coefi<-coef(object, id=id)
    xvars<-names(coef)
    mat[, xvars]%*%coefi
}
```


We now try to choose among the models of different sizes using cross-validation. This approach is somewhat involved, as we must perform best subset selection within each of the k training sets. First, we create a vector that allocates each observaton to one of k=10 folds, and we create a matrix in which we will store the results.
```{r cv, echo=TRUE, include=TRUE} 
k<-10
set.seed(1)
folds<-sample(1:k, nrow(Hitters), replace=TRUE)
cv.errors<-matrix(NA, nrow=k,ncol=19)
```

Now we write a for loop that performs cross-validation. In the jth fold, the elements of folds that equal j are in the test set, and the remainder are in the training set. We make our predicctions for each model size, compute the test errors on the appropriate subset, and store them in the appropriate slot in the matrix cv.errors.
```{r cv2, echo=TRUE, include=TRUE} 
for (j in 1:k) {
    best.fit<-regsubsets(Salary~., data=Hitters[folds!=j,], nvmax=19)
    for (i in 1:19) {
        pred<-predict(best.fit, Hitters[folds==j,],id=i)
        cv.errors[j,i]<-mean((Hitters$Salary[folds==j]-pred)^2)
    }
}
```

This has given us a 10*19 matrix, of which the (i,j)th element corresponds to the test MSE for the ith cross-validation fold for the best j-variable model. We use the apply() function to average over the columns of this matrix in order to obtain a vector for which the jth element is the cross-validation error for the j-variable model. 

```{r cv3, echo=TRUE, include=TRUE} 
mean.cv.errors<-apply(cv.errors, 2, mean)
mean.cv.errors
```

We see that cross-validation selects an 11-variable model. We now perform best subset selection on the full data set in order to obtain the 11-variable model.

```{r cv4, echo=TRUE, include=TRUE} 
reg.best<-regsubsets(Salary~., data=Hitters, nvmax=19)
coef(reg.best,11)
```
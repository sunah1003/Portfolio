---
title: "<center> PCR and PLS Regression </center>"
output:
  html_document:
    fig_height: 4
    highlight: pygments
    theme: spacelab
  pdf_document: default
---
<center> <h3> Sunah Park </center>

This markdown file is created by Sunah Park for extended lab exercises in the book _An Introduction to Statistical Learning with Applications in R_ [(ISLR)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf). 


* * *

### Setup for code chunks
```{r mychunksetup, echo=TRUE, include=TRUE} 
rm(list=ls())
# default r markdown global options in document
knitr::opts_chunk$set(
   ########## Text results ##########
    echo=TRUE, 
    warning=FALSE, # to preserve warnings in the output 
    error=FALSE, # to preserve errors in the output
    message=FALSE, # to preserve messages
    strip.white=TRUE, # to remove the white lines in the beginning or end of a source chunk in the output 

    ########## Cache ##########
    cache=TRUE,
   
    ########## Plots ##########
    fig.path="", # prefix to be used for figure filenames
    fig.width=8,
    fig.height=6,
    dpi=200
)
```



* * * 
```{r lib, echo=TRUE, include=TRUE} 
library(pls) # pcr() function, plsr() function
library(ISLR)
library(ggplot2)
```


```{r df, echo=TRUE, include=TRUE} 
head(Hitters,3)
Hitters<-na.omit(Hitters)
```

* * *
## __Principal Components Regression__
Principal components regression (PCR) can be performed using the pcr() function, which is part of the pls library. We now apply PCR to the Hitters data, in order to predict Salary. The syntax for the pcr() function is similar to that for lm(), with a few additional options. Setting scale=TRUE has the effect of standardizing each predictor prior to generating the principal components, so that the scale on which each variable is measured will not have an effect. Setting validation="CV" causes pcr() to compute the ten-fold cross-validation error for each possible value of M, the number of principal components used. The resulting fit can be examined using summary().

```{r pcr, echo=TRUE, include=TRUE} 
set.seed(1)
pcr.fit<-pcr(Salary~., data=Hitters, scale=TRUE, validation="CV") 
summary(pcr.fit)
```

The CV score is provided for each possible number of components, ranging from M=0 onwards. Note that pcr() reports the root mean squared error; in order to obtain the usual MSE, we must square this quantity.
One can also plot the cross-validation scores using the validationplot() function. Using val.type="MSEP" will cause the cross-validation MSE to be plotted.

```{r pcr-plot, echo=TRUE, include=TRUE} 
validationplot(pcr.fit, val.type="MSEP")
summary(pcr.fit)
```

The smallest CV error occurs when M=16 components are used. This is barely fewer than M=19, which amounts to simply performing least squares, because when all of the components are used in PCR no dimension reduction occurs. 

However, from the plot we also see that the CV error is roughly the same when only one component is included in the model. This suggests that a model that uses just a small number of components might suffice.

The summary() function also provides the percentage of variance explained in the predictors and in the response using different numbers of components. Setting M=1 only captures 38,31% of all the variance, or information, in the predictors. In contrast, using M=6 increases the value to 88.63%. If we were to use all M=p=19 components, this would increase to 100%. 

We now perform PCR on the training data and evaluate its test set performance.
```{r pcr2, echo=TRUE, include=TRUE} 
x<-model.matrix(Salary~., data=Hitters)[,-1]
y<-Hitters$Salary

set.seed(1)
train<-sample(1:nrow(x),size=nrow(x)/2)
test<--train
y.test<-y[test]

pcr.fit<-pcr(Salary~., data=Hitters, subset=train, scale=TRUE, validation="CV")
validationplot(pcr.fit, val.type="MSEP", type="b")
```

We find that the lowest cross-validation error occurs when M=7 component are used. 
```{r pcr3, echo=TRUE, include=TRUE} 
pcr.pred<-predict(pcr.fit, x[test,], ncomp=7)
mean((pcr.pred-y.test)^2)
```

This test set MSE is competitive with the results obtained using ridge regression and the lasso. However, as a result of the way PCR is implemented, the final model is more difficult to interpret because it does not perform any kind of variable selection or even direclty produce coefficient estimates. 

Now we fit PCR on the full data set, using M=7, the number of components identified by cross-validation.
```{r pcr4, echo=TRUE, include=TRUE} 
pcr.fit<-pcr(y~x, scale=TRUE, ncomp=7)
summary(pcr.fit)
```


* * * 
## __Partial Least Squares__
We implement partial least squares(PLS) using the plsr() function. 
```{r pls, echo=TRUE, include=TRUE} 
set.seed(1)
pls.fit<-plsr(Salary~., data=Hitters, subset=train, scale=TRUE, validation="CV")
summary(pls.fit)
validationplot(pls.fit, val.type="MSEP", type="b")
```

The lowest cross-validation error occurs when only M=2 partial least squares directions are used. 
```{r pls2, echo=TRUE, include=TRUE} 
pls.pred<-predict(pls.fit, x[test,], ncomp=2)
mean((pls.pred-y.test)^2)
```

The test MSE is comparable to but slightly higher than the test MSE obtained using PCR.

Finally, we perform PLS using the full data set, using M=2, the number of components identified by cross-validation.
```{r pls3, echo=TRUE, include=TRUE} 
pls.fit<-plsr(y~x, scale=TRUE, ncomp=2)
summary(pls.fit)
```

Notice that the percentage of variance in Salary that two-component PLS fit explains 46.4% is almost as much as that explained using the final seven-component model PCR fit, 46.69%. This is because PCR only attempts to maximize the amount of variance explained in the predictors, while PLS searches for directions that explain variance in both the predictors and the response.